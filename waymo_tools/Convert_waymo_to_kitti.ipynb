{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pVhOfzLx9us"
      },
      "source": [
        "#Waymo Open Dataset \n",
        "\n",
        "- Website: https://waymo.com/open\n",
        "- GitHub: https://github.com/waymo-research/waymo-open-dataset\n",
        "\n",
        "\n",
        "This notebook demonstratea how to read the labels, and to extract panoptic labels with consistent instance ID tracks for any number of frames but they are all converted to match the kitti step dataset format.\n",
        "\n",
        "This notebook mainly relies on the Waymo Open Dataset library for processing.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sPLur9kMaLh"
      },
      "source": [
        "# Package Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTP04tYwNOIq"
      },
      "outputs": [],
      "source": [
        "!pip3 install waymo-open-dataset-tf-2-11-0==1.5.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s31F-VVWLa7z"
      },
      "outputs": [],
      "source": [
        "#@markdown ## (Optional) Install a minimal version of deeplab2 for the WOD.\n",
        "# Please ignore this cell if you already have deeplab2 installed\n",
        "\n",
        "# This shell script will download and install only those deeplab2 modules which\n",
        "# are used by the WOD.\n",
        "# They are used here https://github.com/waymo-research/waymo-open-dataset/blob/master/src/waymo_open_dataset/bazel/deeplab2.BUILD\n",
        "!wget https://raw.githubusercontent.com/waymo-research/waymo-open-dataset/master/src/waymo_open_dataset/pip_pkg_scripts/install_deeplab2.sh -O - | bash\n",
        "\n",
        "# Refer to the instructions on how intall the entire deeplab2 if you need other\n",
        "# deeplab2 modules as well.\n",
        "# https://github.com/google-research/deeplab2/blob/main/g3doc/setup/installation.md"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --ignore-installed Pillow==9.0.0"
      ],
      "metadata": {
        "id": "TwfL5pXAKmNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqs8_62VNc4T"
      },
      "source": [
        "# Imports and global definitions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The tfrecords of the waymo dataset are extracted from the official data saved on google cloud. \n",
        "\n",
        "To extract them, you have to have an account on the waymo dataset"
      ],
      "metadata": {
        "id": "9C9ccWrPkJw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud auth login"
      ],
      "metadata": {
        "id": "T4wh1Z6mTe2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt = open(\"/content/waymo.txt\", \"r\")\n",
        "files = txt.read().split(\"\\n\")\n",
        "files = files[61:71]\n",
        "# files = files[0]"
      ],
      "metadata": {
        "id": "UYIgcBFWjXCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(files)"
      ],
      "metadata": {
        "id": "p33jKSFs185w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file in files:\n",
        "  !gsutil cp gs://$file /content/training"
      ],
      "metadata": {
        "id": "I30j3aFeTF2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuNAlbQpNkLa"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "folder_path = \"/content/training\" \n",
        "FILE_NAMES  = [os.path.join(folder_path, file) for file in os.listdir(folder_path)]\n",
        "FILE_NAMES "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCDNLdp9Ni8a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from typing import Any, Dict, Iterator, List, Optional, Sequence, Tuple\n",
        "import immutabledict\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import multiprocessing as mp\n",
        "import numpy as np\n",
        "import dask.dataframe as dd\n",
        "\n",
        "if not tf.executing_eagerly():\n",
        "  tf.compat.v1.enable_eager_execution()\n",
        "\n",
        "from waymo_open_dataset import dataset_pb2 as open_dataset\n",
        "from waymo_open_dataset import v2\n",
        "from waymo_open_dataset.protos import camera_segmentation_metrics_pb2 as metrics_pb2\n",
        "from waymo_open_dataset.protos import camera_segmentation_submission_pb2 as submission_pb2\n",
        "from waymo_open_dataset.wdl_limited.camera_segmentation import camera_segmentation_metrics\n",
        "from waymo_open_dataset.utils import camera_segmentation_utils\n",
        "from PIL import Image\n",
        "from waymo_open_dataset import dataset_pb2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process Waymo data \n",
        "\n",
        "We process the Waymo data to Kitti format which is based on the Coco format. \n",
        "\n",
        "The channels of the image are formatted as follows:\n",
        "```\n",
        "Red Channel = semantic_id\n",
        "Green Channel = instance_id // 256\n",
        "Blue Channel  = instance % 256\n",
        "```\n",
        "\n",
        "Each dataset has different labels ids so these ids are mapped to each other to be matched together. To ensure tracking, the glbal mapping ids were calculated using the Waymo library. The global ids are consistant throughout each video sequence and throughout the 5 different cameras.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "R1G0JwW7AXo8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define label maps for waymmo and kitti \n",
        "\n",
        "waymo_label = [\"void\",\"TYPE_EGO_VEHICLE\", \"car\", \"truck\", \"bus\",\"large_vehicles\",\"bicycle\",\"motorcycle\",\"trailer\", \"person\",\"cyclist\",\"motorcyclist\",\"bird\", \"animal\",\"cone_pole\", \"pole\", \"person_obj\", \"traffic_sign\", \"traffic_light\", \"building\", \"road\", \"road1\",\"road2\", \"sidewalk\", \"vegetation\", \"sky\", \"ground\", \"TYPE_DYNAMIC\",\"TYPE_STATIC\"]\n",
        "waymo_label_map = {label: x for x, label in enumerate(waymo_label)}\n",
        "kitti_label= [\"road\", \"sidewalk\", \"building\", \"wall\", \"fence\", \"pole\", \"traffic_light\", \"traffic_sign\", \"vegetation\",\"terrain\", \"sky\", \"person\", \"rider\", \"car\", \"truck\", \"bus\", \"train\", \"motorcycle\", \"bicycle\", \"void\"  ]\n",
        "kitti_label_map = {label: x for x, label in enumerate(kitti_label)}\n",
        "kitti_label_map[\"void\"] = 255"
      ],
      "metadata": {
        "id": "TaZP8TpQ5wge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0  ## change this to the last saved count \n",
        "for FILE_NAME in FILE_NAMES:\n",
        "  dataset = tf.data.TFRecordDataset(FILE_NAME, compression_type='')\n",
        "  frames_with_seg = []\n",
        "  for data in dataset:\n",
        "    sequence_id = None\n",
        "    frame = open_dataset.Frame()\n",
        "    frame.ParseFromString(bytearray(data.numpy()))\n",
        "\n",
        "    # Save frames which contain CameraSegmentationLabel messages. We assume that\n",
        "    # if the first image has segmentation labels, all images in this frame will.\n",
        "    if frame.images[0].camera_segmentation_label.panoptic_label:\n",
        "      \n",
        "      if sequence_id is None:\n",
        "        sequence_id = frame.images[0].camera_segmentation_label.sequence_id\n",
        "      for index, image in enumerate(frame.images):\n",
        "         \n",
        "          if(index == 0):\n",
        "            count += 1\n",
        "            string_count = '{:05d}'.format(count)\n",
        "          \n",
        "          #get RGB images\n",
        "          \n",
        "          im = tf.image.decode_jpeg(image.image)\n",
        "          \n",
        "          image_name = \"waymo_out/\"+ str(sequence_id[-6:]) + \"_\" + str(image.name) + string_count + \"_leftImg8bit\" + \".png\"\n",
        "          \n",
        "          tf.keras.preprocessing.image.save_img(image_name, im)\n",
        "\n",
        "         #get global id for tracking instances \n",
        "          global_id_mapping = camera_segmentation_utils._remap_global_ids(\n",
        "              [image.camera_segmentation_label], remap_to_sequential=False)\n",
        "          if global_id_mapping:\n",
        "            max_instance_id = max(\n",
        "                [max([global_id for _, global_id in mapping.items()])\n",
        "                for _, mapping in global_id_mapping.items()])\n",
        "      \n",
        "          #get semantic and instances labels for processing \n",
        "          panoptic_labels = camera_segmentation_utils.decode_single_panoptic_label_from_proto(image.camera_segmentation_label)\n",
        "          semantic_label, instance_label = camera_segmentation_utils.decode_semantic_and_instance_labels_from_panoptic_label(panoptic_labels, image.camera_segmentation_label.panoptic_label_divisor)\n",
        "          \n",
        "          instance_label_copy = np.copy(instance_label)\n",
        "\n",
        "          # use waymo library functions to map the instance labels to global labels\n",
        "          if True:\n",
        "            if isinstance(image.camera_segmentation_label, v2.CameraSegmentationLabelComponent):\n",
        "              mapping_iter = camera_segmentation_utils._iterate_over_mapping(label)\n",
        "            elif isinstance(image.camera_segmentation_label, dataset_pb2.CameraSegmentationLabel):\n",
        "              mapping_iter = image.camera_segmentation_label.instance_id_to_global_id_mapping\n",
        "            else:\n",
        "              raise ValueError('Input label format not supported.')\n",
        "            for mapping in mapping_iter:\n",
        "              instance_mask = (instance_label == mapping.local_instance_id)\n",
        "              instance_label_copy[instance_mask] = global_id_mapping[image.camera_segmentation_label.sequence_id][\n",
        "                  mapping.global_instance_id]\n",
        "          if np.amax(instance_label) >= image.camera_segmentation_label.panoptic_label_divisor:\n",
        "            raise ValueError('A panoptic_label_divisor of '\n",
        "                            f'{image.camera_segmentation_label.panoptic_label_divisor} is requested, but the '\n",
        "                            'maximum instance id exceeds this.')\n",
        "          \n",
        "          instance_label_copy = instance_label_copy + 1\n",
        "          \n",
        "          # use the label maps to map waymo labels into kitti labels\n",
        "          inverted_dict= {v: k for k, v in waymo_label_map.items()}\n",
        "          \n",
        "          new_semantic_labels = semantic_label.copy()\n",
        "          for idx, label in np.ndenumerate(semantic_label):\n",
        "            key = inverted_dict.get(label)\n",
        "            if key == \"person_obj\":\n",
        "                key = \"person\"\n",
        "            if key == \"road1\" or key == \"road2\":\n",
        "                key = \"road\"\n",
        "            if key in kitti_label_map.keys():\n",
        "              new_semantic_labels[idx] = kitti_label_map[key]\n",
        "            else: \n",
        "              new_semantic_labels[idx] = kitti_label_map[\"void\"]\n",
        "         \n",
        "         #format the images to be similar to kitti and concantenate the channels\n",
        "\n",
        "          R = new_semantic_labels\n",
        "          G = instance_label_copy // 256\n",
        "          B = instance_label_copy % 256\n",
        "          panoptic_label_rgb = np.dstack((R,G,B))\n",
        "          im = Image.fromarray((panoptic_label_rgb).astype(np.uint8))\n",
        "              \n",
        "          image_name = \"waymo_out/\" + str(sequence_id[-6:]) + \"_\" + str(image.name) + string_count + \"_panoptic\" + \".png\"\n",
        "          im.save(image_name)\n",
        "    "
      ],
      "metadata": {
        "id": "N2TzDHd1pq-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### uncomment to visualise images \n",
        "\n",
        "\n",
        "# panoptic_label_rgb = camera_segmentation_utils.panoptic_label_to_rgb(semantic_label, instance_label)\n",
        "    # plt.figure(figsize=(64, 60))\n",
        "    # plt.imshow(panoptic_label_rgb)\n",
        "    # plt.grid(False)\n",
        "    # plt.axis('off')\n",
        "    # plt.show()"
      ],
      "metadata": {
        "id": "0V7QwkCnmIcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "DgBozMcQ4C-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save folder in google drive\n",
        "\n",
        "!cp -r \"/content/waymo_out7\" \"/content/drive/MyDrive/waymo_new/\""
      ],
      "metadata": {
        "id": "TTUeGAet4DcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l96pswEOp7o8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}